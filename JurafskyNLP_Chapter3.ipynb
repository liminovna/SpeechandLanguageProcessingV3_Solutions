{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1By8s3bVhuWUhjyoAU6g2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liminovna/SpeechandLanguageProcessingV3_Solutions/blob/main/JurafskyNLP_Chapter3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Write out the equation for trigram probability estimation"
      ],
      "metadata": {
        "id": "59Ruee-hoZyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P(w_n|w_{n-2}w_{n-1}) = \\frac{C(w_{n-2}w_{n-1}w_n)}{C(w_{n-2}w_{n-1})}$"
      ],
      "metadata": {
        "id": "UHXuOT9NkyPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now write out all the non-zero trigram probabilities for the *I am Sam* corpus\n",
        "\n",
        "    <s> I am Sam </s>\n",
        "    <s> Sam I am </s>\n",
        "    <s> I do not like green eggs and ham </s>"
      ],
      "metadata": {
        "id": "T8z8qZb1mHol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrigramModel():\n",
        "  def __init__(self, corpus):\n",
        "    # self.unigrams = {}\n",
        "    self.bigrams = {}\n",
        "    self.trigrams = {}\n",
        "\n",
        "    for s in corpus:\n",
        "      words = s.lower().split()\n",
        "      # # appending unigrams\n",
        "      # for w in words:\n",
        "      #   if w not in self.unigrams.keys():\n",
        "      #     self.unigrams[w] = 1\n",
        "      #   else:\n",
        "      #     self.unigrams[w] += 1\n",
        "      # appending bigrams\n",
        "      cntr = 0\n",
        "      for i in range(len(words)-1):\n",
        "        cur_bigram = (words[cntr] + ' ' + words[cntr+1])\n",
        "        if cur_bigram not in self.bigrams:\n",
        "          self.bigrams[cur_bigram] = 1\n",
        "        else:\n",
        "          self.bigrams[cur_bigram] += 1\n",
        "        cntr += 1\n",
        "      # appending trigrams\n",
        "      cntr = 0\n",
        "      for i in range(len(words)-2):\n",
        "        cur_trigram = (words[cntr] + ' ' + words[cntr+1] + ' ' + words[cntr+2])\n",
        "        if cur_trigram not in self.trigrams:\n",
        "          self.trigrams[cur_trigram] = 1\n",
        "        else:\n",
        "          self.trigrams[cur_trigram] += 1\n",
        "        cntr += 1\n",
        "\n",
        "  # def add1smoothing_proba(self, s):\n",
        "  #   s = s.lower()\n",
        "  #   words = s.split()\n",
        "  #   return (self.trigrams[s] + 1) / (self.unigrams[words[0]]+len(self.unigrams))\n",
        "\n",
        "  def unsmoothed_proba(self, s):\n",
        "    s = s.lower()\n",
        "    words = s.split()\n",
        "    return self.trigrams[s]/self.bigrams[words[0] + ' ' + words[1]]"
      ],
      "metadata": {
        "id": "0UL8k6V1oYr5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    '<s> I am Sam </s>',\n",
        "    '<s> Sam I am </s>',\n",
        "    '<s> I do not like green eggs and ham </s>',\n",
        "]\n",
        "\n",
        "model = TrigramModel(corpus=corpus)"
      ],
      "metadata": {
        "id": "NWONzZD_ojNu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Answer: ')\n",
        "for t in model.trigrams.keys():\n",
        "  print(f'P({t}) = {model.unsmoothed_proba(t)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkItmVP9qQqs",
        "outputId": "5ff3e256-6f8e-445e-f0cd-5d2b72c7249e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \n",
            "P(<s> i am) = 0.5\n",
            "P(i am sam) = 0.5\n",
            "P(am sam </s>) = 1.0\n",
            "P(<s> sam i) = 1.0\n",
            "P(sam i am) = 1.0\n",
            "P(i am </s>) = 0.5\n",
            "P(<s> i do) = 0.5\n",
            "P(i do not) = 1.0\n",
            "P(do not like) = 1.0\n",
            "P(not like green) = 1.0\n",
            "P(like green eggs) = 1.0\n",
            "P(green eggs and) = 1.0\n",
            "P(eggs and ham) = 1.0\n",
            "P(and ham </s>) = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Calculate the probability of the sentence *i want chinese food*. Give two probabilities -- unsmoothed and an add-one probability. Assume the additional add-1 smoothed probabilities $P(i|<s>)=0.19$ and $P(</s>|food)=0.40$."
      ],
      "metadata": {
        "id": "cku9pk3nqyMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = '<s> I want chinese food <\\s>'\n",
        "unsmoothed_proba = 0.25*0.33*0.0065*0.52*0.68\n",
        "addone_proba = 0.19*0.21*0.0029*0.52*0.4\n",
        "print('Answer\\n',\\\n",
        "      'Unsmoothed probability:', \"{:.5f}\".format(unsmoothed_proba), '\\n',\\\n",
        "      'Add-one probability:', \"{:.7f}\".format(addone_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AobKG_ylquZ1",
        "outputId": "95a6f470-16d9-4ff8-b373-9a12d40d006d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer\n",
            " Unsmoothed probability: 0.00019 \n",
            " Add-one probability: 0.0000241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Which of the two probabilities you computed in the previous exercise is higher, unsmoothed or smoothed? Explain why."
      ],
      "metadata": {
        "id": "m8DG8qbgrR97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "The unsmoothed probability is higher because we did not give away any bit of it to the events we have not seen, unlike smoothed probability which is what's left after we've 'shaved off' some of the probability mass."
      ],
      "metadata": {
        "id": "MfjiptJzrVWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 We are given the following corpus:\n",
        "\n",
        "    '<s> i am sam </s>',\n",
        "    '<s> sam i am </s>',\n",
        "    '<s> i am sam </s>',\n",
        "    '<s> i do not like green eggs and sam </s>',\n",
        "\n",
        "Using a bigram language model with add-one smoothing, what is P(Sam|am)? Include \\<s> and \\<\\s> in your counts just like any other token."
      ],
      "metadata": {
        "id": "5WeQvLshhizt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramModel():\n",
        "  def __init__(self, corpus):\n",
        "    self.unigrams = {}\n",
        "    self.bigrams = {}\n",
        "\n",
        "    for s in corpus:\n",
        "      words = s.split()\n",
        "      # appending unigrams\n",
        "      for w in words:\n",
        "        if w not in self.unigrams.keys():\n",
        "          self.unigrams[w] = 1\n",
        "        else:\n",
        "          self.unigrams[w] += 1\n",
        "      # appending bigrams\n",
        "      cntr = 0\n",
        "      for i in range(len(words)-1):\n",
        "        cur_bigram = (words[cntr] + ' ' + words[cntr+1])\n",
        "        if cur_bigram not in self.bigrams:\n",
        "          self.bigrams[cur_bigram] = 1\n",
        "        else:\n",
        "          self.bigrams[cur_bigram] += 1\n",
        "        cntr += 1\n",
        "\n",
        "  def add1smoothing_proba(self, s):\n",
        "    s = s.lower()\n",
        "    words = s.split()\n",
        "    return (self.bigrams[s] + 1) / (self.unigrams[words[0]]+len(self.unigrams))\n",
        "\n",
        "  def unsmoothed_proba(self, s):\n",
        "    s = s.lower()\n",
        "    words = s.split()\n",
        "    return self.bigrams[s]/self.unigrams[words[0]]"
      ],
      "metadata": {
        "id": "spPwRUYfi2r5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    '<s> i am sam </s>',\n",
        "    '<s> sam i am </s>',\n",
        "    '<s> i am sam </s>',\n",
        "    '<s> i do not like green eggs and sam </s>',\n",
        "]\n",
        "\n",
        "model = BigramModel(corpus=corpus)\n",
        "print('Answer: ', round(model.add1smoothing_proba('am Sam'), 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XlSBp6kmb4D",
        "outputId": "f985b204-d74b-479d-8c94-e7fe5b53186a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  0.214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Suppose we didn't use the end-symbol \\<\\s>. Train an unsmoothed bigram grammar on the following training corpus without using the end-symbol \\<\\s>:\n",
        "\n",
        "    '<s> a b',\n",
        "    '<s> b b',\n",
        "    '<s> b a',\n",
        "    '<s> a a'"
      ],
      "metadata": {
        "id": "AzUni4fUp7KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    '<s> a b',\n",
        "    '<s> b b',\n",
        "    '<s> b a',\n",
        "    '<s> a a'\n",
        "]\n",
        "\n",
        "model = BigramModel(corpus=corpus)\n",
        "model.unsmoothed_proba('a a') + model.unsmoothed_proba('a b') + model.unsmoothed_proba('b b') + model.unsmoothed_proba('b a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANABYHY4qnkR",
        "outputId": "03bd424f-cccf-4459-d6c8-5e74ef4b6b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6 Suppose we train a trigram language model with add-one smoothing on a given corpus. The corpus contains V word types. Express a formula for estimating $P(w3,w1,w2)$, where $w3$ is a word which follows the bigram $(w1,w2)$, in terms of various n-gram counts and V."
      ],
      "metadata": {
        "id": "IntqWohrwE3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P_{add-one} (w3|w1w2) = \\frac{C(w1w2w3)+1}{C(w1w2)+V_2}$\n",
        "\n",
        ", where $V_2$ is the number of unique bigrams in the corpus"
      ],
      "metadata": {
        "id": "BX5ykyKlwhYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.7 We are given the following corpus, modified from the one in the chapter:\n",
        "    '<s> i am sam </s>',\n",
        "    '<s> sam i am </s>',\n",
        "    '<s> i am sam </s>',\n",
        "    '<s> i do not like green eggs and sam </s>',\n",
        "\n",
        "If we use linear interpolation smoothing between a maximum-likelihood bigram\n",
        "model and a maximum-likelihood unigram model with $\\lambda_1 = \\frac{1}{2}$ and $\\lambda_2 = \\frac{1}{2}$ , what is $P(Sam|am)$? Include <s> and </s> in your counts just like any other token."
      ],
      "metadata": {
        "id": "YQDyNKlJzCuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VciWU2ruwaNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}